# Resultados de votaciones de Servel por medio de web scraping

Flujo de R que scrapea datos desde el Servel, limpia los datos, y retorna visualizaciones en gr√°ficos y tablas.

----

## Elecciones presidenciales y de diputados/as 2025

Scripts:
1. `servel_scraping_presidenciales.R`
2. `servel_limpiar_presidenciales.R`

----

## Elecciones Regionales 2024: Gobernadores regionales

![Mapa de resultados comunales de elecci√≥n de gobernadores 2024](selecci√≥n/servel_mapa_rm_p_resultados_2024-11-25.jpg)

Por las elecciones de Gobernadores de 2¬™ vuelta, nuevamente hice una peque√±a cobertura en tiempo real de los resultados electorales. 

Modifiqu√© el sistema de web scrapping y generaci√≥n autom√°tica de gr√°ficos y tablas que us√© para las elecciones regionales de octubre, esta vez enfoc√°ndome en resultados comunales y ventajas porcentuales. En menos de media hora ya hab√≠a adaptado el sistema de la elecci√≥n anterior para obtener los datos nuevos, ubicados en un sitio distinto, y adaptados a una elecci√≥n de caracter√≠sticas diferentes. Mientras los datos se iban scrapeando autom√°ticamente, pude dedicarme a desarrollar nuevas visualizaciones para presentar los resultados, conectar estas visualizaciones al flujo de trabajo, y empezar a obtenerlas de forma autom√°tica.

![resultados comunales de elecci√≥n de gobernadores 2024](selecci√≥n/servel_grafico_barras_2024-11-25.jpg)

Lamentablemente para mi (pero afortunadamente para el Servel) el conteo fue extremadamente r√°pido, as√≠ que solo pude hacer 3 o 4 actualizaciones de datos/visualizaciones y los conteos ya hab√≠an llegado a sobre el 95% de mesas escrutadas ü•≤

![](selecci√≥n/servel_tabla_Independencia_24-11-24_2003.png)

Es demasiado satisfactorio cuando se llega a un flujo de trabajo y procesamiento de datos donde solo se necesita especificar uno o dos par√°metros, presionas ejecutar, y el sistema corre solo, entreg√°ndote resultados unos segundos m√°s tarde con el sonido de una campanita. Y gracias a un desarrollo precabido, es posible tomar sistemas que fueron desarrollados para un fin, y adaptarlos para otro nuevo objetivo.

Todo el sistema de obtenci√≥n de datos y visualizaci√≥n fue desarrollado en R.

![](selecci√≥n/servel_grafico_Santiago_24-11-24_2003.jpg)

----

## Elecciones Municipales 2024: Alcaldes

![](selecci√≥n/servel_resultados_multi_28-10-24_1054_c2.png)


Con motivo de las elecciones municipales, estuve generando algunas visualizaciones ‚Äùen tiempo real‚Äù de los resultados de las elecciones de alcald√≠as. 

![](selecci√≥n/servel_grafico_Pe√±alolen_28-10-24_0101.jpg)

Los datos de conteo de votos los fui obteniendo minuto a minuto mediante web scraping con {RSelenium}, que permite programar un navegador web para que interact√∫e con un sitio como si fuera humano. Entonces, el navegador robot (marioneta, le llaman) iba apretando todos los botones, sin intervenci√≥n de mi parte, para encontrar y copiar los resultados de cada comuna del pa√≠s.

![](selecci√≥n/servel_tabla_Las_Condes_28-10-24_0006.png)

Los nuevos resultados llegaban con frecuencia, as√≠ que hab√≠a que echar a correr el proceso bajo presi√≥n, cada 10 minutos aprox. Todo iba bien: presionaba ejecutar, el proceso pasaba por todas las comunas, limpiaba los datos y retornaba visualizaciones. Hasta que, en la mitad del conteo, el sitio del Servel cambi√≥! Por alg√∫n motivo, cambiaron a una versi√≥n similar del sitio, pero que internamente funcionaba distinto, entonces se desconfigur√≥ todo el web scraping. Tuve que luchar contra el tiempo para reestablecerlo (terrible para mi, porque estaba aprendiendo Selenium üò≠). Lo otro que me jug√≥ en contra fue que no se me ocurri√≥ automatizar la redacci√≥n de textos y posteo en redes sociales, que al final fue lo que me quit√≥ m√°s tiempo üòí

Tambi√©n falt√≥ hacer visualizaciones m√°s entretenidas, pero se hizo lo que se pudo para una idea que sali√≥ a la r√°pida. Es gratificante hacer andar un flujo largo de procesamiento de datos solo con un par de comandos, desde la obtenci√≥n de los datos hasta que te arroja decenas o cientos de salidas ‚ú®

![](selecci√≥n/servel_grafico_Puente_Alto_27-10-24_2314.jpg)

Para los nerds, us√© {RSelenium} para un script que recib√≠a un vector de comunas e iteraba por ellas con {furrr}, y retornaba una lista con la tabla de resultados, el p√°rrafo de las mesas escrutadas, y el nombre de la comuna. Luego, otro script de R cargaba el scraping m√°s reciente y limpiaba los datos, calculaba porcentajes, coincid√≠a partidos con sectores pol√≠ticos, correg√≠a a "independientes" que en realidad tienen sector pol√≠tico claro, arreglaba nombres (Servel usa e√±es pero no tildes, por alguna raz√≥n), interpretaba el texto de las mesas como cifras individuales, sumaba votos nulos y blancos, entre otras cosas. Despu√©s ten√≠a un script desde el que comandaba todos los dem√°s pasos, que para partir borraba todas las salidas antiguas, y seg√∫n las comunas que le ped√≠a, generaba nuevos gr√°ficos/tablas en una carpeta nueva. Sobre los gr√°ficos y tablas, nada interesante, salvo que el alto de los gr√°ficos depend√≠a de la cantidad de candidatos, para que siempre mantuvieran espaciados correctos y no se deformaran si eran muchos o muy pocos candidatos/as.

Finalmente, el flujo de procesamientos de datos en R gener√≥ 238 gr√°ficos y 240 tablas, de las cuales les comparto algunas. Esa fue mi experiencia intentando generar reportes en tiempo real sobre datos de elecciones. Para la siguiente votaci√≥n espero tener algo m√°s elaborado!


## Alcaldes electos en la Regi√≥n Metropolitana
![](selecci√≥n/servel_tabla_ganadores_rm_28-10-24_1054.png)

## Alcaldes de izquierda electos
![](selecci√≥n/servel_tabla_ganadores_izq_28-10-24_1054.png)


----

## Funcionamiento

Los scripts `servel_scraping_x.R` realizan un web scraping (utilizando `{RSelenium}`) del sitio del Servel indicado que contengan los resultados. Los primeros pasos que los scrapping son apretar que el navegador automatizado y controlado por Selenium entre los resultados deseados, seleccione la desagregaci√≥n geogr√°fica, y obtenga las comunas disponibles para ver sus resultados. Luego se realiza una alteraci√≥n a trav√©s de todas las comunas disponibles, donde el navegador automatizado entra a cada una de las comunas, da unos segundos de espera, y descarga la tabla de resultados y los p√°rrafos de texto sobre las mesas escrutadas.

Posteriormente, el script `servel_limpiar.R` realiza una serie de operaciones de limpieza procesamiento de datos para dejar los datos disponibles para su visualizaci√≥n y an√°lisis. √âste script carga autom√°ticamente los datos scrapeados m√°s recientes, permitiendo poder hacer un scraping constante y luego ejecutar este script para dejar los datos procesados. Dentro de este script:

- Calcular las mesas escrutadas a partir de la extracci√≥n de texto de un p√°rrafo
- Categorizar las filas de datos que no corresponden a candidatos, sino a actos y a votos nulos o blancos
- Enviar las filas de informaci√≥n de pactos y votos totales a columnas
- Sumar los votos nulos y blancos en una sola categor√≠a
- Calcular los porcentajes de votos y de mesas
- Clasificar los partidos pol√≠ticos por sectores pol√≠ticos
- Corregir determinados candidatos pol√≠ticos a sectores pol√≠ticos espec√≠ficos, en consideraci√≥n de que √∫ltimamente muchos candidatos pol√≠ticos de marcada ideolog√≠a y trayectoria en partidos pol√≠ticos se postulan como independientes
- Corregir los nombres de algunos candidatos y candidatas, en consideraci√≥n de qu√© el servil no incluye tildes en sus datos

Teniendo los datos procesados, se puede ejecutar el script `generar.R`, al cual se le especifica un vector de comunas de inter√©s, y el script autom√°ticamente produce gr√°ficos y tablas para las comunas especificadas. Las visualizaciones resultantes se guardan en la carpeta apropiada para la elecci√≥n, dentro de la carpeta del tipo de visualizaci√≥n correspondiente, y tambi√©n son copiados a la carpeta `salidas`. La carpeta `salidas` es vaciada de contenidos cada vez que se ejecuta el script `generar.R`, asumiendo que no son necesarias las visualizaciones anteriores, dado que las visualizaciones generadas ser√≠an versiones actualizadas de las mismas, o de comunas distintas. Esto es muy √∫til para ir haciendo un reporte en tiempo real de los resultados, debido a que la ejecuci√≥n del script `generar.R` producir√≠a visualizaciones con los datos actualizados, y solamente de las comunas que deseas comunicar a continuaci√≥n, ofreci√©ndotelas en una carpeta donde es f√°cil encontrarlas.

Tambi√©n se pueden ejecutar otros scripts de visualizaci√≥n de datos agrupados tales como:
- `grafico_barras.R`, que genera un gr√°fico de barras con los porcentajes de candidaturas por comuna
- `torta_x.R` que produce visualizaciones de torta o dona con la cantidad total de votos por sector, por partido, etc.
- `mapa_chile.R` que genera un mapa de Chile continental con resultados por comuna
- `mapa_rm.R`, `mapa_gobernadores_rm.R`, y `mapa_gobernadores_rm_p.R`, que generan mapas de la Regi√≥n Metropolitana (per√≠metro urbano de la zona urbana de las comunas de la regi√≥n metropolitana) con resultados por comuna, y con diferencia o margen de votos 


----

La licencia de este c√≥digo permite el uso libre del mismo por parte de individuos y organizaciones, siempre y cuando vuelvan a publicar el c√≥digo bajo la misma licencia si es que realizan cambios o mejoras al c√≥digo. No se permite el uso comercial, privado, o remunerado de estos datos ni de este c√≥digo. Para usar este c√≥digo para servicios remunerados o por parte de privados, deben [ponerse en contacto conmigo.](https://bastianolea.rbind.io/contact/)